{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b30e5243",
   "metadata": {},
   "source": [
    "# Prediction Results with Audio Annotations on Summary Vectronics Data\n",
    "\n",
    "**Last Modified**: Jul 29, 2025\n",
    "\n",
    "In this notebook, we summarize and visualize the results for behavior classification with audio annotations on summary sttaistics of Vectronics acceleration data. The training and testing data splits are created randomly for this experiment. We conduct hyperparameter tuning and look at the prediction results f the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f6b8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44eef854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import AutoDateLocator, AutoDateFormatter\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "from scipy.stats import wasserstein_distance\n",
    "from datetime import datetime\n",
    "from matplotlib.dates import DateFormatter\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.utils.data_prep import (combined_annotations,\n",
    "                                create_matched_data,\n",
    "                                create_max_windows,\n",
    "                                create_summary_data,\n",
    "                                create_data_splits,\n",
    "                                setup_dataloaders,\n",
    "                                give_balanced_weights)\n",
    "\n",
    "from src.utils.io import (get_matched_data_path,\n",
    "                          get_matched_metadata_path,\n",
    "                          get_matched_summary_path,\n",
    "                          get_metadata_path,\n",
    "                          get_video_labels_path,\n",
    "                          get_audio_labels_path,\n",
    "                          get_figures_dir,\n",
    "                          get_project_root,\n",
    "                          get_results_dir,\n",
    "                          )\n",
    "\n",
    "from config.settings import (RAW_COLLAPSE_BEHAVIORS_MAPPING_W_TROTTING,\n",
    "                             RAW_COLLAPSE_BEHAVIORS_MAPPING_WO_TROTTING,\n",
    "                             RAW_BEHAVIORS_W_TROTTING,\n",
    "                             RAW_BEHAVIORS_WO_TROTTING,\n",
    "                             SAMPLING_RATE,\n",
    "                             id_mapping\n",
    "                             )\n",
    "\n",
    "from src.utils.functionalities import (sliced_wasserstein_distance,\n",
    "                                      ot_align,\n",
    "                                      minmax_scale)\n",
    "from config.paths import (HISTORIC_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045c4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.markersize'] = 12\n",
    "mpl.rcParams['lines.linewidth'] = 1\n",
    "mpl.rcParams['xtick.labelsize'] = 20\n",
    "mpl.rcParams['ytick.labelsize'] = 20\n",
    "mpl.rcParams[\"axes.labelsize\"] = 22\n",
    "mpl.rcParams['legend.fontsize'] = 18\n",
    "mpl.rcParams['axes.titlesize'] = 25\n",
    "mpl.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f0bf1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "163c81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load matched acceleration and label pairs data, metadata, and summary\n",
    "\n",
    "all_annotations = combined_annotations(video_path=get_video_labels_path(), \n",
    "                                        audio_path=get_audio_labels_path(),\n",
    "                                        id_mapping=id_mapping) # load annotations \n",
    "\n",
    "all_annotations.Timestamp_start = pd.to_datetime(all_annotations.Timestamp_start)\n",
    "all_annotations.Timestamp_end = pd.to_datetime(all_annotations.Timestamp_end)\n",
    "all_annotations['duration'] = (all_annotations.Timestamp_end - all_annotations.Timestamp_start).dt.total_seconds()\n",
    "all_annotations['Behavior'] = all_annotations['Behavior'].replace(RAW_COLLAPSE_BEHAVIORS_MAPPING_WO_TROTTING)\n",
    "all_annotations = all_annotations[all_annotations.Behavior.isin(RAW_BEHAVIORS_WO_TROTTING)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd23ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    10170.000000\n",
      "mean        32.534612\n",
      "std         96.290787\n",
      "min          0.000000\n",
      "25%          3.000000\n",
      "50%          8.000000\n",
      "75%         23.000000\n",
      "max       2466.000000\n",
      "Name: duration, dtype: float64\n",
      "Value 30s is approximately at the 80.03th percentile.\n"
     ]
    }
   ],
   "source": [
    "print(all_annotations[\"duration\"].describe())\n",
    "value = 30\n",
    "quantile = np.mean(all_annotations[\"duration\"] <= value)\n",
    "print(f\"Value {value}s is approximately at the {quantile*100:.2f}th percentile.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37cdc2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(get_metadata_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ae3079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_duration = 20\n",
    "\n",
    "dir = os.path.join(get_project_root(), 'data', f\"duration{min_duration}\")\n",
    "os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "summary_path = os.path.join(dir, \"matched_acc_summary.csv\")\n",
    "data_path = os.path.join(dir, \"matched_acc_data.csv\")\n",
    "metadata_path = os.path.join(dir, \"matched_acc_metadata.csv\")\n",
    "\n",
    "if not (os.path.exists(summary_path) and os.path.exists(data_path) and os.path.exists(metadata_path)):\n",
    "    acc_summary, acc_data, acc_data_metadata = create_matched_data(\n",
    "        metadata, all_annotations, min_duration=min_duration, verbose=True\n",
    "    )\n",
    "    acc_summary.to_csv(summary_path, index=False)\n",
    "    acc_data.to_csv(data_path, index=False)\n",
    "    acc_data_metadata.to_csv(metadata_path, index=False)\n",
    "else:\n",
    "    acc_summary = pd.read_csv(summary_path)\n",
    "    acc_data = pd.read_csv(data_path)\n",
    "    acc_data_metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "    acc_data['acc_x'] = acc_data['acc_x'].apply(json.loads)\n",
    "    acc_data['acc_y'] = acc_data['acc_y'].apply(json.loads)\n",
    "    acc_data['acc_z'] = acc_data['acc_z'].apply(json.loads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2321fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
