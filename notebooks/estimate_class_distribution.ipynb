{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc0b748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "464dc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import config as cfg\n",
    "from src.utils.io import get_results_path\n",
    "import config as config\n",
    "from src.utils.online_eval import all_online_eval\n",
    "from collections import Counter\n",
    "\n",
    "# Script imports\n",
    "from src.utils.io import (get_results_path,\n",
    "                          get_metadata_path,\n",
    "                            get_matched_data_path)\n",
    "\n",
    "from src.utils.data_prep import (adjust_behavior_and_durations,\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fdb697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.markersize'] = 12\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['xtick.labelsize'] = 25\n",
    "mpl.rcParams['ytick.labelsize'] = 25\n",
    "mpl.rcParams[\"axes.labelsize\"] = 25\n",
    "mpl.rcParams['legend.fontsize'] = 25\n",
    "mpl.rcParams['axes.titlesize'] = 25\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "device = 'cuda:3' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b597b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_duration = 12.937\n",
    "window_length = int(window_duration * cfg.SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "592973dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_behavior_proportions_optimized(data_folder: str, behaviors: list):\n",
    "    \"\"\"\n",
    "    Computes behavior proportions by first getting daily counts from each file\n",
    "    before combining, making it highly memory-efficient.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): The path to the folder containing the CSV files.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isdir(data_folder):\n",
    "        print(f\"Error: Folder not found at '{data_folder}'\")\n",
    "        return\n",
    "\n",
    "    # A list to hold the daily count DataFrames from each file\n",
    "    all_daily_counts = []\n",
    "\n",
    "    print(\"Reading files and calculating daily counts...\")\n",
    "    # Loop through all .csv files in the specified folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                filename_stem = os.path.splitext(filename)[0]\n",
    "                parts = filename_stem.split('_')\n",
    "                individual_name = parts[0]\n",
    "                date_str = parts[1]\n",
    "\n",
    "                # Read only the necessary column\n",
    "                behavior_col = pd.read_csv(file_path, usecols=['Most probable behavior'])\n",
    "                \n",
    "                if behavior_col.empty:\n",
    "                    continue\n",
    "\n",
    "                # Calculate the value counts for this file immediately\n",
    "                daily_counts = behavior_col['Most probable behavior'].value_counts()\n",
    "\n",
    "                # Convert this small summary Series into a DataFrame\n",
    "                counts_df = daily_counts.reset_index()\n",
    "                counts_df.columns = ['behavior', 'count']\n",
    "                \n",
    "                # Add the metadata\n",
    "                counts_df['individual'] = individual_name\n",
    "                counts_df['date'] = pd.to_datetime(date_str)\n",
    "                \n",
    "                # Append the small summary DataFrame to our list\n",
    "                all_daily_counts.append(counts_df)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process file '{file_path.name}'. Reason: {e}\")\n",
    "\n",
    "    if not all_daily_counts:\n",
    "        print(\"No valid data files were found to process.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate the list of daily summaries\n",
    "    counts_summary_df = pd.concat(all_daily_counts, ignore_index=True)\n",
    "\n",
    "    # Add a month column for the final aggregation\n",
    "    counts_summary_df['month'] = counts_summary_df['date'].dt.to_period('M')\n",
    "\n",
    "    print(\"\\nAggregating counts and calculating final proportions...\")\n",
    "    # Sum the daily counts to get monthly totals\n",
    "    monthly_totals = counts_summary_df.groupby(\n",
    "        ['individual', 'month', 'behavior']\n",
    "    )['count'].sum()\n",
    "\n",
    "    wide_df = monthly_totals.unstack(level='behavior')\n",
    "    wide_df = wide_df.reindex(columns=behaviors, fill_value=0)\n",
    "    wide_df = wide_df.fillna(0)\n",
    "    final_df = wide_df.reset_index().round(2)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a38fd1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files and calculating daily counts...\n",
      "\n",
      "Aggregating counts and calculating final proportions...\n",
      "\n",
      "--- Monthly Behavior Proportions ---\n",
      "behavior individual    month     Feeding     Moving    Running  Stationary\n",
      "0               ash  2021-03    0.000000   0.000000   0.000000  100.000000\n",
      "1               ash  2021-08    1.427320   0.201401   0.000000   98.371278\n",
      "2               ash  2021-10    0.745714   8.349208   1.038424   89.866654\n",
      "3               ash  2021-11    1.172513   7.629580   1.339257   89.858650\n",
      "4               ash  2021-12    1.087518   5.271076   1.302266   92.339140\n",
      "..              ...      ...         ...        ...        ...         ...\n",
      "63            palus  2022-06   15.817318  64.604257  19.578425    0.000000\n",
      "64            palus  2022-07   93.789477   4.851069   1.359454    0.000000\n",
      "65            palus  2022-08  100.000000   0.000000   0.000000    0.000000\n",
      "66            palus  2022-09  100.000000   0.000000   0.000000    0.000000\n",
      "67            palus  2022-10  100.000000   0.000000   0.000000    0.000000\n",
      "\n",
      "[68 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(cfg.VECTRONICS_BEHAVIOR_EVAL_PATH, 'evals')\n",
    "monthly_counts = calculate_monthly_behavior_proportions_optimized(data_folder, cfg.RAW_BEHAVIORS)\n",
    "monthly_proportions = monthly_counts.copy()\n",
    "# 3. Print the results\n",
    "if monthly_counts is not None:\n",
    "    print(\"\\n--- Monthly Behavior Proportions ---\")\n",
    "    row_totals = monthly_proportions[cfg.RAW_BEHAVIORS].sum(axis=1)\n",
    "    monthly_proportions[cfg.RAW_BEHAVIORS] = monthly_proportions[cfg.RAW_BEHAVIORS].div(row_totals, axis=0).fillna(0)*100\n",
    "    print(monthly_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c0d493c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monthly Behavior Proportions on Valid Months ---\n",
      "behavior individual    month   Feeding    Moving   Running  Stationary\n",
      "2               ash  2021-10  0.745714  8.349208  1.038424   89.866654\n",
      "3               ash  2021-11  1.172513  7.629580  1.339257   89.858650\n",
      "4               ash  2021-12  1.087518  5.271076  1.302266   92.339140\n",
      "5               ash  2022-01  0.735552  4.363854  1.685616   93.214978\n",
      "6               ash  2022-02  1.007428  3.461600  1.035483   94.495489\n",
      "7               ash  2022-03  1.316724  3.492554  1.215349   93.975372\n",
      "8               ash  2022-04  0.987513  3.433691  1.064254   94.514542\n",
      "9               ash  2022-05  1.472397  4.395826  0.989104   93.142672\n",
      "10              ash  2022-06  0.721172  1.266507  0.321379   97.690941\n",
      "11              ash  2022-07  0.885547  1.888053  1.071645   96.154755\n",
      "12              ash  2022-08  1.169179  3.734383  1.932209   93.164229\n",
      "13              ash  2022-09  0.615497  0.593137  1.462246   97.329120\n",
      "14              ash  2022-10  1.270899  3.576812  1.401498   93.750791\n",
      "15              ash  2022-11  1.191382  4.779881  0.627270   93.401467\n",
      "17           fossey  2022-07  1.192867  6.011634  2.398020   90.397479\n",
      "18           fossey  2022-08  1.199820  4.663817  2.605112   91.531251\n",
      "19           fossey  2022-09  1.342984  4.475437  2.198357   91.983222\n",
      "20           fossey  2022-10  1.456891  5.141195  1.942331   91.459582\n",
      "21           fossey  2022-11  1.344291  5.714859  2.449478   90.491372\n",
      "22           fossey  2022-12  1.303527  6.278167  3.626680   88.791626\n",
      "23           fossey  2023-01  1.171630  5.510512  2.055381   91.262476\n",
      "24           fossey  2023-02  1.821920  5.831580  2.610941   89.735559\n",
      "45           jessie  2022-08  0.782390  5.296833  2.472761   91.448016\n",
      "46           jessie  2022-09  0.672703  4.466797  1.379829   93.480671\n",
      "47           jessie  2022-10  0.810118  6.133344  1.289055   91.767483\n",
      "48           jessie  2022-11  0.679347  7.612871  1.295350   90.412432\n",
      "49           jessie  2022-12  0.708470  6.795128  1.466421   91.029981\n",
      "50           jessie  2023-01  0.916765  6.630086  1.554392   90.898756\n",
      "51           jessie  2023-02  0.809928  7.703648  1.408354   90.078069\n",
      "52           jessie  2023-03  0.561285  5.604791  0.894967   92.938957\n"
     ]
    }
   ],
   "source": [
    "monthly_proportions_valid = monthly_proportions[(monthly_proportions[cfg.RAW_BEHAVIORS] > 0.05).all(axis=1)]\n",
    "print(\"\\n--- Monthly Behavior Proportions on Valid Months ---\")\n",
    "print(monthly_proportions_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ae08565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_class_distribution(df: pd.DataFrame, behavior_cols: list, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimates class distribution and constructs a confidence interval using bootstrapping.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns for individual, month, and behavior counts.\n",
    "        behavior_cols (list): A list of the column names that contain behavior counts.\n",
    "        n_iterations (int): The number of bootstrap samples to generate.\n",
    "        alpha (float): The significance level for the confidence interval (e.g., 0.05 for 95% CI).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the overall proportion, and the lower and\n",
    "                      upper bounds of the confidence interval for each behavior.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate the Overall Proportion (Point Estimate) ---\n",
    "    # Sum the counts for each behavior across the entire dataset\n",
    "    total_counts = df[behavior_cols].sum().values\n",
    "    # Get the grand total of all observations\n",
    "    grand_total = total_counts.sum()\n",
    "    # Calculate the proportion for each behavior\n",
    "    overall_proportions = total_counts / grand_total\n",
    "\n",
    "    # --- 2. Perform Bootstrapping to get a distribution of proportions ---\n",
    "    bootstrap_proportions_list = []\n",
    "\n",
    "    print(f\"Running {len(df)} bootstrap iterations...\")\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        # Calculate proportions for this specific bootstrap sample\n",
    "        sample_total_counts = row[behavior_cols].values\n",
    "        sample_grand_total = sample_total_counts.sum()\n",
    "        \n",
    "        # Avoid division by zero if a sample happens to be empty or all zeros\n",
    "        if sample_grand_total == 0:\n",
    "            continue\n",
    "            \n",
    "        sample_proportions = sample_total_counts / sample_grand_total\n",
    "\n",
    "        bootstrap_proportions_list.append(sample_proportions)\n",
    "\n",
    "    # Convert the list of results into a DataFrame\n",
    "    bootstrap_df = pd.DataFrame(bootstrap_proportions_list)\n",
    "\n",
    "    # --- 3. Calculate the Confidence Interval from the bootstrap distribution ---\n",
    "    lower_quantile = alpha / 2.0  # e.g., 0.05 / 2 = 0.025\n",
    "    upper_quantile = 1.0 - (alpha / 2.0) # e.g., 1 - 0.025 = 0.975\n",
    "\n",
    "    # Find the proportions at these percentiles\n",
    "    ci_lower = bootstrap_df.quantile(lower_quantile)\n",
    "    ci_upper = bootstrap_df.quantile(upper_quantile)\n",
    "\n",
    "    # --- 4. Combine results into a final DataFrame ---\n",
    "    result_df = pd.DataFrame({\n",
    "        'behavior': behavior_cols,\n",
    "        'overall_proportion': overall_proportions*100,\n",
    "        'ci_lower_bound': ci_lower*100,\n",
    "        'ci_upper_bound': ci_upper*100\n",
    "    })\n",
    "\n",
    "    return result_df.round(4) # Round for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbdde271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 30 bootstrap iterations...\n",
      "            overall_proportion  ci_lower_bound  ci_upper_bound\n",
      "behavior                                                      \n",
      "Feeding                 1.0243          0.6006          1.5685\n",
      "Moving                  4.8962          1.0813          7.8812\n",
      "Running                 1.6199          0.5431          2.8903\n",
      "Stationary             92.4597         89.4760         97.4286\n"
     ]
    }
   ],
   "source": [
    "monthly_counts = monthly_counts[(monthly_counts[cfg.RAW_BEHAVIORS] != 0).all(axis=1)]\n",
    "result_df = bootstrap_class_distribution(monthly_counts, cfg.RAW_BEHAVIORS, alpha = 0.05)\n",
    "result_df = result_df.set_index('behavior')\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ba40674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION SUMMARY FOR MATCHED ANNOTATIONS\n",
      "behavior\n",
      "Feeding        4.0269\n",
      "Moving        10.7502\n",
      "Running        5.4570\n",
      "Stationary    68.0157\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "acc_data = pd.read_csv(get_matched_data_path())\n",
    "acc_data = adjust_behavior_and_durations(acc_data, cfg.RAW_COLLAPSE_BEHAVIORS_MAPPING, cfg.RAW_BEHAVIORS)\n",
    "\n",
    "# Group and sum durations in hours\n",
    "duration_table = np.round(acc_data.groupby('behavior')['duration'].sum().div(3600), 4)\n",
    "\n",
    "print(\"DURATION SUMMARY FOR MATCHED ANNOTATIONS\")\n",
    "print(duration_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95edfd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding: Outside CI\n",
      "Moving: Outside CI\n",
      "Running: Outside CI\n",
      "Stationary: Outside CI\n"
     ]
    }
   ],
   "source": [
    "within_ci = (duration_table >= result_df['ci_lower_bound']) & (duration_table <= result_df['ci_upper_bound'])\n",
    "for behavior, is_within in within_ci.items():\n",
    "    print(f\"{behavior}: {'Within CI' if is_within else 'Outside CI'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
