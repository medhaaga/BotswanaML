{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc0b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464dc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import config as cfg\n",
    "from src.utils.io import get_results_path\n",
    "import config as config\n",
    "from src.utils.online_eval import all_online_eval\n",
    "from collections import Counter\n",
    "\n",
    "# Script imports\n",
    "from src.utils.io import (get_results_path,\n",
    "                          get_metadata_path,\n",
    "                            get_matched_data_path)\n",
    "\n",
    "from src.utils.data_prep import (adjust_behavior_and_durations,\n",
    "                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdb697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing Parameters\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['lines.markersize'] = 12\n",
    "mpl.rcParams['lines.linewidth'] = 2\n",
    "mpl.rcParams['xtick.labelsize'] = 25\n",
    "mpl.rcParams['ytick.labelsize'] = 25\n",
    "mpl.rcParams[\"axes.labelsize\"] = 25\n",
    "mpl.rcParams['legend.fontsize'] = 25\n",
    "mpl.rcParams['axes.titlesize'] = 25\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "device = 'cuda:3' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b597b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_duration = 12.937\n",
    "window_length = int(window_duration * cfg.SAMPLING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592973dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_monthly_behavior_proportions_optimized(data_folder: str, behaviors: list):\n",
    "    \"\"\"\n",
    "    Computes behavior proportions by first getting daily counts from each file\n",
    "    before combining, making it highly memory-efficient.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): The path to the folder containing the CSV files.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isdir(data_folder):\n",
    "        print(f\"Error: Folder not found at '{data_folder}'\")\n",
    "        return\n",
    "\n",
    "    # A list to hold the daily count DataFrames from each file\n",
    "    all_daily_counts = []\n",
    "\n",
    "    print(\"Reading files and calculating daily counts...\")\n",
    "    # Loop through all .csv files in the specified folder\n",
    "    for filename in os.listdir(data_folder):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(data_folder, filename)\n",
    "            try:\n",
    "                filename_stem = os.path.splitext(filename)[0]\n",
    "                parts = filename_stem.split('_')\n",
    "                individual_name = parts[0]\n",
    "                date_str = parts[1]\n",
    "\n",
    "                # Read only the necessary column\n",
    "                behavior_col = pd.read_csv(file_path, usecols=['Most probable behavior'])\n",
    "                \n",
    "                if behavior_col.empty:\n",
    "                    continue\n",
    "\n",
    "                # Calculate the value counts for this file immediately\n",
    "                daily_counts = behavior_col['Most probable behavior'].value_counts()\n",
    "\n",
    "                # Convert this small summary Series into a DataFrame\n",
    "                counts_df = daily_counts.reset_index()\n",
    "                counts_df.columns = ['behavior', 'count']\n",
    "                \n",
    "                # Add the metadata\n",
    "                counts_df['individual'] = individual_name\n",
    "                counts_df['date'] = pd.to_datetime(date_str)\n",
    "                \n",
    "                # Append the small summary DataFrame to our list\n",
    "                all_daily_counts.append(counts_df)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process file '{file_path.name}'. Reason: {e}\")\n",
    "\n",
    "    if not all_daily_counts:\n",
    "        print(\"No valid data files were found to process.\")\n",
    "        return\n",
    "\n",
    "    # Concatenate the list of daily summaries\n",
    "    counts_summary_df = pd.concat(all_daily_counts, ignore_index=True)\n",
    "\n",
    "    # Add a month column for the final aggregation\n",
    "    counts_summary_df['month'] = counts_summary_df['date'].dt.to_period('M')\n",
    "\n",
    "    print(\"\\nAggregating counts and calculating final proportions...\")\n",
    "    # Sum the daily counts to get monthly totals\n",
    "    monthly_totals = counts_summary_df.groupby(\n",
    "        ['individual', 'month', 'behavior']\n",
    "    )['count'].sum()\n",
    "\n",
    "    wide_df = monthly_totals.unstack(level='behavior')\n",
    "    wide_df = wide_df.reindex(columns=behaviors, fill_value=0)\n",
    "    wide_df = wide_df.fillna(0)\n",
    "    final_df = wide_df.reset_index().round(2)\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38fd1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files and calculating daily counts...\n",
      "\n",
      "Aggregating counts and calculating final proportions...\n"
     ]
    }
   ],
   "source": [
    "data_folder = os.path.join(cfg.VECTRONICS_BEHAVIOR_EVAL_PATH, 'evals')\n",
    "monthly_counts = calculate_monthly_behavior_proportions_optimized(data_folder, cfg.RAW_BEHAVIORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8755fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Monthly Behavior Proportions ---\n",
      "behavior individual    month   Feeding    Moving      Other   Running  \\\n",
      "0               ash  2021-11  1.146879  7.063233   2.682364  1.298418   \n",
      "1               ash  2021-12  1.081003  4.803409   3.426880  1.230433   \n",
      "2               ash  2022-03  1.284879  2.969720   3.028603  1.136559   \n",
      "3               ash  2022-08  1.145587  3.196755   3.163977  1.855052   \n",
      "4               ash  2022-10  1.239500  3.238477   3.172363  1.337282   \n",
      "5            fossey  2022-07  1.142771  5.274560   2.283737  2.302994   \n",
      "6            fossey  2022-08  1.037647  3.726297   2.831563  2.472335   \n",
      "7            fossey  2022-09  1.182402  3.649425   2.584746  2.071358   \n",
      "8            fossey  2022-10  1.370061  4.498533   2.907351  1.802302   \n",
      "9            fossey  2022-11  1.119906  4.717842   3.093375  2.316731   \n",
      "10           fossey  2022-12  1.160440  5.196703   4.017932  3.425213   \n",
      "11           fossey  2023-01  1.018781  4.763386   3.537960  1.937573   \n",
      "12           fossey  2023-02  1.671527  5.120198   4.034165  2.438408   \n",
      "13            green  2021-09  1.429082  6.050409   2.451328  2.021451   \n",
      "14            green  2021-10  1.128068  3.948517   3.939621  1.922553   \n",
      "15            green  2021-11  1.378796  4.538775   4.925090  2.601458   \n",
      "16            green  2021-12  1.381529  5.650546   4.724528  2.634737   \n",
      "17            green  2022-01  1.604293  3.328019   4.299594  2.846398   \n",
      "18            green  2022-02  2.032030  2.172870   3.698123  1.484046   \n",
      "19            green  2022-03  2.033697  2.635862   4.312370  1.795386   \n",
      "20            green  2022-04  1.838575  3.438933   4.527843  1.891959   \n",
      "21            green  2022-05  1.594453  2.488347   3.837799  1.880010   \n",
      "22            green  2022-06  1.121640  1.656329   4.662302  1.081438   \n",
      "23            green  2022-07  1.236880  2.380410   4.646911  2.058688   \n",
      "24            green  2022-08  1.016704  3.163512   3.504822  2.477556   \n",
      "25            green  2022-09  1.143845  2.589307   4.278935  1.511530   \n",
      "26            green  2022-10  1.286447  3.464238   4.715120  1.320900   \n",
      "27            green  2022-11  1.053788  3.688896  19.051208  1.092107   \n",
      "28            palus  2021-10  1.912772  7.208425   2.336797  1.115978   \n",
      "29            palus  2021-11  1.881700  7.922435   2.525395  1.449317   \n",
      "30            palus  2021-12  2.817496  8.289727   3.029697  2.107012   \n",
      "31            palus  2022-01  2.968053  6.875462   2.369776  2.105357   \n",
      "32            palus  2022-02  2.244185  5.179030   2.537547  1.228182   \n",
      "33            palus  2022-03  1.914253  5.229477   3.330778  1.237099   \n",
      "34            palus  2022-05  2.862439  5.861104   2.751336  1.976964   \n",
      "35            palus  2022-06  1.882540  6.901112   2.231563  2.223513   \n",
      "\n",
      "behavior  Stationary  \n",
      "0          87.809106  \n",
      "1          89.458276  \n",
      "2          91.580240  \n",
      "3          90.638629  \n",
      "4          91.012378  \n",
      "5          88.995938  \n",
      "6          89.932158  \n",
      "7          90.512068  \n",
      "8          89.421752  \n",
      "9          88.752145  \n",
      "10         86.199713  \n",
      "11         88.742299  \n",
      "12         86.735701  \n",
      "13         88.047729  \n",
      "14         89.061240  \n",
      "15         86.555881  \n",
      "16         85.608661  \n",
      "17         87.921696  \n",
      "18         90.612930  \n",
      "19         89.222685  \n",
      "20         88.302690  \n",
      "21         90.199390  \n",
      "22         91.478291  \n",
      "23         89.677111  \n",
      "24         89.837405  \n",
      "25         90.476382  \n",
      "26         89.213295  \n",
      "27         75.114001  \n",
      "28         87.426029  \n",
      "29         86.221153  \n",
      "30         83.756069  \n",
      "31         85.681352  \n",
      "32         88.811055  \n",
      "33         88.288393  \n",
      "34         86.548157  \n",
      "35         86.761273  \n"
     ]
    }
   ],
   "source": [
    "row_sums = monthly_counts[cfg.SUMMARY_BEHAVIORS].sum(axis=1)\n",
    "\n",
    "valid_monthly_counts = monthly_counts[\n",
    "    (monthly_counts[cfg.SUMMARY_BEHAVIORS]\n",
    "     .gt(0.01 * row_sums, axis=0)  # compare each column to 1% of row sum\n",
    "     .all(axis=1))                  # keep only rows where all columns satisfy condition\n",
    "].reset_index(drop=True)\n",
    "\n",
    "monthly_proportions = valid_monthly_counts.copy()\n",
    "if monthly_counts is not None:\n",
    "    print(\"\\n--- Monthly Behavior Proportions ---\")\n",
    "    row_totals = monthly_proportions[cfg.RAW_BEHAVIORS].sum(axis=1)\n",
    "    monthly_proportions[cfg.RAW_BEHAVIORS] = monthly_proportions[cfg.RAW_BEHAVIORS].div(row_totals, axis=0).fillna(0)*100\n",
    "    print(monthly_proportions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ae08565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_class_distribution(df: pd.DataFrame, behavior_cols: list, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimates class distribution and constructs a confidence interval using bootstrapping.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with columns for individual, month, and behavior counts.\n",
    "        behavior_cols (list): A list of the column names that contain behavior counts.\n",
    "        n_iterations (int): The number of bootstrap samples to generate.\n",
    "        alpha (float): The significance level for the confidence interval (e.g., 0.05 for 95% CI).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the overall proportion, and the lower and\n",
    "                      upper bounds of the confidence interval for each behavior.\n",
    "    \"\"\"\n",
    "    # --- 1. Calculate the Overall Proportion (Point Estimate) ---\n",
    "    # Sum the counts for each behavior across the entire dataset\n",
    "    total_counts = df[behavior_cols].sum().values\n",
    "    # Get the grand total of all observations\n",
    "    grand_total = total_counts.sum()\n",
    "    # Calculate the proportion for each behavior\n",
    "    overall_proportions = total_counts / grand_total\n",
    "\n",
    "    # --- 2. Perform Bootstrapping to get a distribution of proportions ---\n",
    "    bootstrap_proportions_list = []\n",
    "\n",
    "    print(f\"Running {len(df)} bootstrap iterations...\")\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        # Calculate proportions for this specific bootstrap sample\n",
    "        sample_total_counts = row[behavior_cols].values\n",
    "        sample_grand_total = sample_total_counts.sum()\n",
    "        \n",
    "        # Avoid division by zero if a sample happens to be empty or all zeros\n",
    "        if sample_grand_total == 0:\n",
    "            continue\n",
    "            \n",
    "        sample_proportions = sample_total_counts / sample_grand_total\n",
    "\n",
    "        bootstrap_proportions_list.append(sample_proportions)\n",
    "\n",
    "    # Convert the list of results into a DataFrame\n",
    "    bootstrap_df = pd.DataFrame(bootstrap_proportions_list)\n",
    "\n",
    "    # --- 3. Calculate the Confidence Interval from the bootstrap distribution ---\n",
    "    lower_quantile = alpha / 2.0  # e.g., 0.05 / 2 = 0.025\n",
    "    upper_quantile = 1.0 - (alpha / 2.0) # e.g., 1 - 0.025 = 0.975\n",
    "\n",
    "    # Find the proportions at these percentiles\n",
    "    ci_lower = bootstrap_df.quantile(lower_quantile)\n",
    "    ci_upper = bootstrap_df.quantile(upper_quantile)\n",
    "\n",
    "    # --- 4. Combine results into a final DataFrame ---\n",
    "    result_df = pd.DataFrame({\n",
    "        'behavior': behavior_cols,\n",
    "        'overall_proportion': overall_proportions*100,\n",
    "        'ci_lower_bound': ci_lower*100,\n",
    "        'ci_upper_bound': ci_upper*100\n",
    "    })\n",
    "\n",
    "    return result_df.round(4) # Round for cleaner output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbdde271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 36 bootstrap iterations...\n",
      "            overall_proportion  ci_lower_bound  ci_upper_bound\n",
      "behavior                                                      \n",
      "Feeding                 1.5332          1.0185          2.8756\n",
      "Moving                  4.4611          2.1083          7.9683\n",
      "Other                   3.6626          2.2772          6.6909\n",
      "Running                 1.9005          1.0908          2.9187\n",
      "Stationary             88.4426         82.6758         91.4910\n"
     ]
    }
   ],
   "source": [
    "result_df = bootstrap_class_distribution(valid_monthly_counts, cfg.RAW_BEHAVIORS, alpha = 0.05)\n",
    "result_df = result_df.set_index('behavior')\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba40674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DURATION SUMMARY FOR MATCHED ANNOTATIONS\n",
      "behavior\n",
      "Feeding        4.0269\n",
      "Moving        10.7502\n",
      "Other          1.0506\n",
      "Running        5.4570\n",
      "Stationary    68.0157\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "acc_data = pd.read_csv(get_matched_data_path())\n",
    "acc_data = adjust_behavior_and_durations(acc_data, cfg.RAW_COLLAPSE_BEHAVIORS_MAPPING, cfg.RAW_BEHAVIORS)\n",
    "\n",
    "# Group and sum durations in hours\n",
    "duration_table = np.round(acc_data.groupby('behavior')['duration'].sum().div(3600), 4)\n",
    "\n",
    "print(\"DURATION SUMMARY FOR MATCHED ANNOTATIONS\")\n",
    "print(duration_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95edfd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feeding: Outside CI\n",
      "Moving: Outside CI\n",
      "Other: Outside CI\n",
      "Running: Outside CI\n",
      "Stationary: Outside CI\n"
     ]
    }
   ],
   "source": [
    "within_ci = (duration_table >= result_df['ci_lower_bound']) & (duration_table <= result_df['ci_upper_bound'])\n",
    "for behavior, is_within in within_ci.items():\n",
    "    print(f\"{behavior}: {'Within CI' if is_within else 'Outside CI'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b5bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
